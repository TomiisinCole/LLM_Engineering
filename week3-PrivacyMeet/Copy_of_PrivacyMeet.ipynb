{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cT3GWOVqouD"
      },
      "source": [
        "# PrivacyMeet: Privacy-First Meeting Minutes Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PrivacyMeet: Privacy-First Meeting Minutes Generator\n",
        "\n",
        "\n",
        "# First, installing dependencies\n",
        "!pip install -q openai-whisper transformers accelerate bitsandbytes gradio\n",
        "!apt-get -qq update && apt-get -qq install -y ffmpeg\n",
        "\n",
        "# Standard imports\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Google Drive integration\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger('PrivacyMeet')\n",
        "\n",
        "# Constants\n",
        "WHISPER_MODEL_SIZE = \"base\"  # Options: tiny, base, small, medium, large\n",
        "LLM_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  # Gated model that you have access to\n",
        "\n",
        "# ============================================================================\n",
        "# Authentication and Setup\n",
        "# ============================================================================\n",
        "\n",
        "# Log in to Hugging Face - use the token you've saved in Colab secrets\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get('TOKEN')  # Make sure this matches your secret name\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    logger.info(\"Successfully logged in to Hugging Face\")\n",
        "else:\n",
        "    logger.warning(\"No Hugging Face token found. Attempting to proceed without authentication.\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================================\n",
        "# Audio Processing\n",
        "# ============================================================================\n",
        "\n",
        "def setup_whisper():\n",
        "    \"\"\"Set up the Whisper model for transcription\"\"\"\n",
        "    logger.info(f\"Loading Whisper {WHISPER_MODEL_SIZE} model...\")\n",
        "    model = whisper.load_model(WHISPER_MODEL_SIZE)\n",
        "    logger.info(\"Whisper model loaded\")\n",
        "    return model\n",
        "\n",
        "def transcribe_audio(audio_path, whisper_model):\n",
        "    \"\"\"Transcribe audio using Whisper\"\"\"\n",
        "    logger.info(f\"Transcribing audio: {audio_path}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    transcription = result[\"text\"]\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    logger.info(f\"Transcription completed in {duration:.2f} seconds\")\n",
        "\n",
        "    return transcription\n",
        "\n",
        "# ============================================================================\n",
        "# LLM Setup and Minutes Generation\n",
        "# ============================================================================\n",
        "\n",
        "def setup_llm():\n",
        "    \"\"\"Set up the LLM for minutes generation\"\"\"\n",
        "    logger.info(f\"Loading LLM model: {LLM_MODEL}\")\n",
        "\n",
        "    # Quantization configuration for efficient loading\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        LLM_MODEL,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=quant_config\n",
        "    )\n",
        "\n",
        "    logger.info(\"LLM model loaded successfully\")\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_minutes(transcription, audio_filename, model, tokenizer):\n",
        "    \"\"\"Generate meeting minutes from transcription with improved title and attendee detection\"\"\"\n",
        "    logger.info(f\"Generating minutes for {audio_filename}\")\n",
        "\n",
        "    # Create system message emphasizing the title and attendee extraction\n",
        "    system_message = \"\"\"You are a professional meeting minutes generator.\n",
        "    Create detailed, well-formatted meeting minutes from the transcript.\n",
        "\n",
        "    IMPORTANT:\n",
        "    1. Create a meaningful, specific title for the meeting based on the content (e.g., \"Minutes of the Denver City Council Meeting\" rather than \"Meeting Minutes\")\n",
        "    2. Extract the full names and titles of all attendees mentioned in the transcript (e.g., \"Councilman Lopez\", \"Councilwoman Ortega\")\n",
        "    3. Format the attendees as a bulleted list\n",
        "    4. Include a  summary, key discussion points, decisions made, and action items\n",
        "    5. Format output in clear markdown with proper headings and structure\"\"\"\n",
        "\n",
        "    # Create user prompt\n",
        "    base_name = os.path.splitext(os.path.basename(audio_filename))[0].replace(\"_\", \" \")\n",
        "    date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    user_prompt = f\"\"\"Based on this transcript, generate professional meeting minutes.\n",
        "\n",
        "The audio file was named: {base_name}\n",
        "Today's date: {date_str}\n",
        "\n",
        "Remember to:\n",
        "1. Create a proper title reflecting the meeting's purpose\n",
        "2. List all attendees with their titles/positions\n",
        "3. Summarize the key points and decisions\n",
        "4. Highlight any action items or follow-ups with owners\n",
        "\n",
        "Transcript:\n",
        "{transcription}\"\"\"\n",
        "\n",
        "    # Prepare input for the model\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    # Generate minutes\n",
        "    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    outputs = model.generate(inputs, max_new_tokens=2000)\n",
        "    response = tokenizer.decode(outputs[0])\n",
        "\n",
        "    # Clean up the response\n",
        "    response = response.split(\"<|end_header_id|>\")[-1].strip()\n",
        "    response = response.replace(\"<|eot_id|>\", \"\")\n",
        "\n",
        "    logger.info(f\"Minutes generation complete\")\n",
        "\n",
        "    return response\n",
        "\n",
        "# ============================================================================\n",
        "# File Handling\n",
        "# ============================================================================\n",
        "\n",
        "def list_audio_files(base_dir=\"/content/drive/MyDrive\", extensions=(\".mp3\", \".wav\", \".m4a\")):\n",
        "    \"\"\"List audio files in Google Drive\"\"\"\n",
        "    audio_files = []\n",
        "\n",
        "    # Recursively search for audio files (limit depth and number for performance)\n",
        "    max_depth = 3\n",
        "    max_files = 20\n",
        "    count = 0\n",
        "\n",
        "    def search_dir(dir_path, current_depth=0):\n",
        "        nonlocal count\n",
        "        if current_depth > max_depth or count >= max_files:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            for item in os.listdir(dir_path):\n",
        "                if count >= max_files:\n",
        "                    return\n",
        "\n",
        "                full_path = os.path.join(dir_path, item)\n",
        "                if os.path.isfile(full_path) and full_path.lower().endswith(extensions):\n",
        "                    audio_files.append(full_path)\n",
        "                    count += 1\n",
        "                elif os.path.isdir(full_path):\n",
        "                    search_dir(full_path, current_depth + 1)\n",
        "        except (PermissionError, FileNotFoundError):\n",
        "            pass  # Skip directories we can't access\n",
        "\n",
        "    search_dir(base_dir)\n",
        "    return audio_files\n",
        "\n",
        "def save_minutes_to_file(minutes_content, audio_path):\n",
        "    \"\"\"Save minutes to a file next to the audio file\"\"\"\n",
        "    try:\n",
        "        base_path = os.path.splitext(audio_path)[0]\n",
        "        minutes_path = f\"{base_path}_minutes.md\"\n",
        "\n",
        "        with open(minutes_path, 'w') as f:\n",
        "            f.write(minutes_content)\n",
        "\n",
        "        return minutes_path\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving minutes: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ============================================================================\n",
        "# Main Processing Function\n",
        "# ============================================================================\n",
        "\n",
        "def process_audio_file(audio_path, whisper_model, llm_model, llm_tokenizer):\n",
        "    \"\"\"Process an audio file to generate meeting minutes\"\"\"\n",
        "    try:\n",
        "        # Transcribe the audio\n",
        "        transcription = transcribe_audio(audio_path, whisper_model)\n",
        "\n",
        "        # Generate minutes with better title and attendee extraction\n",
        "        minutes = generate_minutes(transcription, audio_path, llm_model, llm_tokenizer)\n",
        "\n",
        "        return minutes\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing audio: {str(e)}\")\n",
        "        return f\"Error processing audio: {str(e)}\"\n",
        "\n",
        "# ============================================================================\n",
        "# Gradio UI\n",
        "# ============================================================================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create Gradio interface with simpler, more reliable implementation\"\"\"\n",
        "    # Set up models\n",
        "    whisper_model = setup_whisper()\n",
        "    llm_model, llm_tokenizer = setup_llm()\n",
        "\n",
        "    # Get available audio files\n",
        "    audio_files = list_audio_files()\n",
        "\n",
        "    with gr.Blocks(title=\"PrivacyMeet - Private Meeting Minutes\") as app:\n",
        "        gr.Markdown(\"# PrivacyMeet\")\n",
        "        gr.Markdown(\"Generate meeting minutes from audio recordings without sharing your data with third parties.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Input options\n",
        "                input_type = gr.Radio(\n",
        "                    [\"Select from Drive\", \"Upload File\"],\n",
        "                    label=\"Input Method\",\n",
        "                    value=\"Select from Drive\"\n",
        "                )\n",
        "\n",
        "                # Drive file selection\n",
        "                file_dropdown = gr.Dropdown(\n",
        "                    label=\"Select Audio File from Drive\",\n",
        "                    choices=audio_files,\n",
        "                    visible=True\n",
        "                )\n",
        "\n",
        "                # File upload\n",
        "                file_upload = gr.Audio(\n",
        "                    label=\"Upload Audio File\",\n",
        "                    type=\"filepath\",\n",
        "                    visible=False\n",
        "                )\n",
        "\n",
        "                refresh_btn = gr.Button(\"Refresh File List\")\n",
        "                process_btn = gr.Button(\"Generate Minutes\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # Status and output\n",
        "                status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "                minutes_output = gr.Markdown(label=\"Generated Minutes\")\n",
        "                save_btn = gr.Button(\"Save to Drive\")\n",
        "                download_btn = gr.Button(\"Download as Markdown\")\n",
        "                saved_path = gr.Textbox(label=\"Saved Location\", visible=True)\n",
        "\n",
        "        # Simple file download component\n",
        "        download_file = gr.File(label=\"Download Minutes\", visible=False)\n",
        "\n",
        "        # Handle input type change\n",
        "        def toggle_input_visibility(input_type_value):\n",
        "            return {\n",
        "                file_dropdown: gr.update(visible=input_type_value == \"Select from Drive\"),\n",
        "                file_upload: gr.update(visible=input_type_value == \"Upload File\")\n",
        "            }\n",
        "\n",
        "        input_type.change(\n",
        "            toggle_input_visibility,\n",
        "            inputs=[input_type],\n",
        "            outputs=[file_dropdown, file_upload]\n",
        "        )\n",
        "\n",
        "        # Handle refreshing the file list\n",
        "        def refresh_files():\n",
        "            new_files = list_audio_files()\n",
        "            return gr.Dropdown(choices=new_files)\n",
        "\n",
        "        refresh_btn.click(\n",
        "            refresh_files,\n",
        "            inputs=[],\n",
        "            outputs=[file_dropdown]\n",
        "        )\n",
        "\n",
        "        # Handle processing the selected file\n",
        "        def process_selected_file(input_type_value, file_path_dropdown, file_path_upload):\n",
        "            # Determine which file path to use\n",
        "            file_path = file_path_dropdown if input_type_value == \"Select from Drive\" else file_path_upload\n",
        "\n",
        "            if not file_path:\n",
        "                return \"Please select an audio file\", \"\"\n",
        "\n",
        "            try:\n",
        "                # Process the file\n",
        "                minutes = process_audio_file(\n",
        "                    file_path,\n",
        "                    whisper_model,\n",
        "                    llm_model,\n",
        "                    llm_tokenizer\n",
        "                )\n",
        "\n",
        "                return \"Minutes generated successfully!\", minutes\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error: {str(e)}\"\n",
        "                return error_msg, \"\"\n",
        "\n",
        "        process_btn.click(\n",
        "            process_selected_file,\n",
        "            inputs=[input_type, file_dropdown, file_upload],\n",
        "            outputs=[status_output, minutes_output]\n",
        "        )\n",
        "\n",
        "        # Handle saving minutes to a file\n",
        "        def save_minutes(input_type_value, file_path_dropdown, file_path_upload, minutes_content):\n",
        "            if not minutes_content:\n",
        "                return \"Please generate minutes first\"\n",
        "\n",
        "            # Determine which file path to use\n",
        "            file_path = file_path_dropdown if input_type_value == \"Select from Drive\" else file_path_upload\n",
        "\n",
        "            if not file_path:\n",
        "                return \"No audio file selected\"\n",
        "\n",
        "            saved_path = save_minutes_to_file(minutes_content, file_path)\n",
        "\n",
        "            if saved_path:\n",
        "                return f\"Minutes saved to {saved_path}\"\n",
        "            else:\n",
        "                return \"Error saving minutes\"\n",
        "\n",
        "        save_btn.click(\n",
        "            save_minutes,\n",
        "            inputs=[input_type, file_dropdown, file_upload, minutes_output],\n",
        "            outputs=[saved_path]\n",
        "        )\n",
        "\n",
        "        # Handle downloading minutes\n",
        "        def create_download_file(minutes_content):\n",
        "            if not minutes_content:\n",
        "                return None\n",
        "\n",
        "            temp_path = \"/tmp/meeting_minutes.md\"\n",
        "            with open(temp_path, 'w') as f:\n",
        "                f.write(minutes_content)\n",
        "\n",
        "            return temp_path\n",
        "\n",
        "        download_btn.click(\n",
        "            create_download_file,\n",
        "            inputs=[minutes_output],\n",
        "            outputs=[download_file]\n",
        "        )\n",
        "\n",
        "    return app\n",
        "\n",
        "# ============================================================================\n",
        "# Main Application\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main application entry point\"\"\"\n",
        "    logger.info(\"Starting PrivacyMeet application\")\n",
        "\n",
        "    # Create and launch the Gradio interface\n",
        "    app = create_gradio_interface()\n",
        "    app.launch(inline=True, share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "bCSVPH5cKiYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}